{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO DE PREDICCIÓN DE SENTIMIENTOS\n",
    "\n",
    "Pasos para crear un modelo de sentimientos:\n",
    "\n",
    "1.- Entendiendo el análisis de sentimientos: El análisis de sentimientos es un área de la inteligencia artificial que se centra en la identificación y extracción de opiniones, emociones o actitudes en textos. Por ejemplo, se puede utilizar para determinar si las opiniones de los clientes sobre un producto son positivas, negativas o neutrales. Esta técnica es especialmente útil para empresas que buscan obtener información valiosa sobre sus productos o servicios, así como para investigadores y científicos de datos que buscan analizar grandes volúmenes de texto.\n",
    "\n",
    "2.- Preparación de los datos: Para entrenar y evaluar un modelo de clasificación de texto, necesitamos un conjunto de datos etiquetados. Esto implica recopilar una serie de textos y asignarles una etiqueta que indique su sentimiento (positivo, negativo o neutral). A menudo, este proceso puede ser costoso y requiere tiempo, pero existen recursos disponibles en línea, como el conjunto de datos de opiniones de películas de IMDb, que podemos utilizar para este propósito.\n",
    "\n",
    "3.- Preprocesamiento de los datos: Antes de alimentar nuestros datos a un modelo de machine learning, es necesario realizar ciertos pasos de preprocesamiento, como:\n",
    "\n",
    "- Convertir todos los textos a minúsculas\n",
    "- Eliminar signos de puntuación y caracteres especiales\n",
    "- Tokenizar el texto en palabras individuales\n",
    "- Eliminar palabras vacías (stop words)\n",
    "- Aplicar lematización o derivación (stemming) para reducir las palabras a su raíz\n",
    "\n",
    "4.- Extracción de características: Una vez que hayamos preprocesado nuestros datos, necesitamos convertirlos en un formato que los modelos de machine learning puedan entender. Para ello, podemos utilizar técnicas como la bolsa de palabras (Bag of Words) o la ponderación de frecuencia inversa de documentos (TF-IDF).\n",
    "\n",
    "5.- Creación y entrenamiento del modelo: Con nuestros datos preprocesados y las características extraídas, podemos crear y entrenar un modelo de clasificación de texto utilizando scikit-learn. Algunos de los algoritmos más comunes para este propósito incluyen la regresión logística, el clasificador Naive Bayes y las máquinas de vectores de soporte (SVM).\n",
    "\n",
    "6.- Evaluación del modelo: Para evaluar el rendimiento de nuestro modelo, podemos utilizar métricas como la precisión, la exhaustividad (recall) y la puntuación F1. También podemos utilizar técnicas de validación cruzada para obtener una estimación más precisa del rendimiento del modelo en datos no vistos.\n",
    "\n",
    "7.- Optimización del modelo: Si el rendimiento de nuestro modelo no es satisfactorio, podemos intentar optimizarlo mediante la selección de características, la ajuste de hiperparámetros o la experimentación con diferentes algoritmos de clasificación.\n",
    "\n",
    "8.- Implementación del modelo: Una vez que hayamos creado y optimizado nuestro modelo de análisis de sentimientos, podemos implementarlo en aplicaciones en tiempo real, como monitoreo de redes sociales, análisis de comentarios de clientes o clasificación de correos electrónicos según su tono emocional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#MODELO QUE DEVUELVE LAS METRICAS DE ACCURACY, PRECISION Y RECALL\n",
    "\n",
    "# Descargar recursos necesarios para NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Leyendo y guardando los datos en un DataFrame\n",
    "positivo = pd.read_csv(\"data/books/positive.review\", names=[\"texto\"])\n",
    "negativo = pd.read_csv(\"data/books/negative.review\", names=[\"texto\"])\n",
    "\n",
    "# Inicializar el stemmer y obtener la lista de stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para procesar el texto\n",
    "def process_text(text):\n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convertir a minúsculas y eliminar stopwords, caracteres especiales y de puntuación\n",
    "    filtered_tokens = [ps.stem(token.lower()) for token in tokens if token.isalnum() and len(token) >= 3 and token.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Aplicar la función a cada texto en positivo y negativo\n",
    "positivo['processed_text'] = positivo['texto'].apply(process_text)\n",
    "negativo['processed_text'] = negativo['texto'].apply(process_text)\n",
    "\n",
    "# Crear una columna para la etiqueta\n",
    "positivo['sentiment'] = 1\n",
    "negativo['sentiment'] = 0\n",
    "\n",
    "# Combinar los datos procesados en un solo DataFrame\n",
    "all_data = pd.concat([positivo[['processed_text', 'sentiment']], negativo[['processed_text', 'sentiment']]], ignore_index=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data['processed_text'], all_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transformar los datos de prueba\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Inicializar y entrenar el clasificador Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir en los datos de prueba\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
